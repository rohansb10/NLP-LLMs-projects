{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9KEOyJ6JVXEk"
      },
      "outputs": [],
      "source": [
        "!pip install -U transformers\n",
        "!pip install -U accelerate\n",
        "!pip install -U datasets\n",
        "!pip install -U bertviz\n",
        "!pip install -U umap-learn"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from datasets import list_datasets\n",
        "\n",
        "\n",
        "all_datasets = list_datasets()"
      ],
      "metadata": {
        "id": "riLVqwKZVnu9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "emotion = load_dataset('emotion')\n",
        "emotion.set_format(type='pandas')"
      ],
      "metadata": {
        "id": "Yig6iiFRVtGI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = emotion['train'][:]\n",
        "df.head()\n",
        ""
      ],
      "metadata": {
        "id": "H-CR-W6PVvbL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classes = emotion['train'].features['label'].names\n",
        "\n",
        "\n",
        "df['label_name'] = df['label'].apply(lambda x: classes[x])\n",
        "\n",
        "\n",
        "df.head()"
      ],
      "metadata": {
        "id": "Rxnxg-DHVxrY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "\n",
        "label_counts = df['label_name'].value_counts(ascending=True)\n",
        "label_counts.plot.barh()\n",
        "plt.title('Frequency of Classes')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "G8Y4ubH5V17T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['Words Per Tweet'] = df['text'].str.split().apply(len)\n",
        "df.boxplot(\"Words Per Tweet\", by='label_name')"
      ],
      "metadata": {
        "id": "fU0TUwLhV427"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer\n",
        "model_ckpt = \"distilbert-base-uncased\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_ckpt)\n",
        "\n",
        "\n",
        "text = \"I love Machine Learning!. Tokenization is awesome\"\n",
        "encoded_text = tokenizer(text)\n",
        "print(encoded_text)\n",
        ""
      ],
      "metadata": {
        "id": "vM0-4uDKV9IT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokens = tokenizer.convert_ids_to_tokens(encoded_text.input_ids)\n",
        "print(tokens)"
      ],
      "metadata": {
        "id": "R78SJm70WAPR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.vocab_size, tokenizer.model_max_length"
      ],
      "metadata": {
        "id": "3uco9QBGWCa8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "emotion.reset_format()\n",
        "\n",
        "\n",
        "# map() method would be used\n",
        "\n",
        "def tokenize(batch):\n",
        "  temp =tokenizer(batch['text'], padding=True, truncation=True)\n",
        "  return temp\n",
        "\n",
        "print(tokenize(emotion[\"train\"][:5]))"
      ],
      "metadata": {
        "id": "Bww7P-RpWEyY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "emotions_encoded = emotion.map(tokenize, batched=True, batch_size=None)\n",
        "\n",
        "\n",
        "emotions_encoded"
      ],
      "metadata": {
        "id": "UzPt_lNwWIL0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text\n"
      ],
      "metadata": {
        "id": "eIXlEfWJWN_0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "inputs = tokenizer(text, return_tensors='pt')\n",
        "inputs"
      ],
      "metadata": {
        "id": "JjNQBRBpWLpF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModel\n",
        "import torch\n",
        "\n",
        "model = AutoModel.from_pretrained(model_ckpt)\n",
        "\n",
        "\n",
        "with torch.no_grad():\n",
        "  outputs = model(**inputs)\n",
        "\n",
        "last_hidden_states = outputs.last_hidden_state\n",
        "\n",
        "\n",
        "last_hidden_states.shape"
      ],
      "metadata": {
        "id": "VZVxk6OrWU65"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForSequenceClassification\n",
        "\n",
        "num_labels = len(classes)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = AutoModelForSequenceClassification.from_pretrained(model_ckpt, num_labels = num_labels).to(device)\n",
        ""
      ],
      "metadata": {
        "id": "TBKk693VWY24"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_labels"
      ],
      "metadata": {
        "id": "4UWYInPmW9yg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import TrainingArguments\n",
        "\n",
        "batch_size = 64\n",
        "model_name = \"distilbert-finetuned-emotion\"\n",
        "\n",
        "training_args = TrainingArguments(output_dir = model_name,\n",
        "                                 num_train_epochs=2,\n",
        "                                 learning_rate = 2e-5,\n",
        "                                 per_device_train_batch_size= batch_size,\n",
        "                                 per_device_eval_batch_size = batch_size,\n",
        "                                  weight_decay=0.01,\n",
        "                                  evaluation_strategy = 'epoch',\n",
        "                                  disable_tqdm=False)\n",
        "\n",
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "\n",
        "def compute_metrics(pred):\n",
        "  labels = pred.label_ids\n",
        "  preds = pred.predictions.argmax(-1)\n",
        "  f1 = f1_score(labels, preds, average='weighted')\n",
        "  acc = accuracy_score(labels, preds)\n",
        "  return {\"accuracy\": acc, \"f1\": f1}\n",
        "\n",
        "from transformers import Trainer\n",
        "\n",
        "trainer = Trainer(model=model, args=training_args,\n",
        "                  compute_metrics=compute_metrics,\n",
        "                  train_dataset=emotions_encoded['train'],\n",
        "                  eval_dataset=emotions_encoded['validation'],\n",
        "                  tokenizer=tokenizer)\n",
        "\n",
        "trainer.train()"
      ],
      "metadata": {
        "id": "zVCd-4BtWkAA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "preds_outputs = trainer.predict(emotions_encoded['test'])\n",
        "preds_outputs.metrics\n",
        ""
      ],
      "metadata": {
        "id": "5Z7Pwel6Wm4H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "y_preds = np.argmax(preds_outputs.predictions, axis=1)\n",
        "y_true = emotions_encoded['test'][:]['label']\n",
        "\n",
        "\n",
        "from sklearn.metrics import classification_report\n",
        "print(classes)\n",
        "print(classification_report(y_true, y_preds))"
      ],
      "metadata": {
        "id": "JZjVeiR0Wq6A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = 'i want to kill you'\n",
        "input_encoded = tokenizer(text, return_tensors='pt').to(device)\n",
        "with torch.no_grad():\n",
        "  outputs = model(**input_encoded)\n",
        "\n",
        "logits = outputs.logits\n",
        "pred = torch.argmax(logits, dim=1).item()\n",
        "pred, classes[pred]"
      ],
      "metadata": {
        "id": "CH54DS8KWtpA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "outputs"
      ],
      "metadata": {
        "id": "NB7f6OsEWvnR"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}