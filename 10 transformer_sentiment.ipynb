{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y00sXwHSkX0S"
      },
      "outputs": [],
      "source": [
        "\n",
        "!pip install -U transformers\n",
        "!pip install -U accelerate\n",
        "!pip install -U datasets\n",
        "!pip install -U bertviz\n",
        "!pip install -U umap-learn"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install spacy\n",
        "!python -m spacy download en_core_web_sm\n",
        "!pip install beautifulsoup4\n",
        "!pip install textblob\n",
        "!pip install mlxtend\n",
        "!pip install git+https://github.com/laxmimerit/preprocess_kgptalkie.git --upgrade --force-reinstall\n",
        ""
      ],
      "metadata": {
        "id": "E1Z3-23pk2oj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# sentiment analysis with the pipeline\n",
        "from transformers import pipeline\n",
        "\n",
        "sentiment_pipeline = pipeline(\"sentiment-analysis\")\n",
        "\n",
        "data = ['i love you', 'i hate you']\n",
        "sentiment_pipeline(data)"
      ],
      "metadata": {
        "id": "-bO_5HfylEfj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "iJj1_g0dlIHv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"IMDB-Dataset.csv\")\n",
        "df = df.sample(10_000)\n",
        "df.head()"
      ],
      "metadata": {
        "id": "Ga_McAYOlLP-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.sentiment.value_counts()"
      ],
      "metadata": {
        "id": "e11wTEhmrzej"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['review'] = df['review'].str.lower()"
      ],
      "metadata": {
        "id": "JLQWj-TemNS1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "class CustomDataset(Dataset):\n",
        "  def __init__(self, texts, labels, tokenizer, max_len=512):\n",
        "    self.texts = texts\n",
        "    self.labels = labels\n",
        "    self.tokenizer = tokenizer\n",
        "    self.max_len = max_len\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.texts)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    text = str(self.texts[idx])\n",
        "    label = torch.tensor(self.labels[idx])\n",
        "\n",
        "    encoding = self.tokenizer(text, truncation=True, padding=\"max_length\",\n",
        "                              max_length=self.max_len)\n",
        "\n",
        "    return {\n",
        "        'input_ids': encoding['input_ids'],\n",
        "        'attention_mask': encoding['attention_mask'],\n",
        "        'labels': label\n",
        "    }\n",
        "\n",
        "\n",
        "\n",
        "# prepare tokenizer and model\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "\n",
        "checkpoint = 'distilbert-base-uncased'\n",
        "device = \"cuda\"\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
        "model = AutoModelForSequenceClassification.from_pretrained(checkpoint, num_labels=2).to(device)\n",
        ""
      ],
      "metadata": {
        "id": "TkAKftralsuo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = df['review'].tolist()\n",
        "\n",
        "label2id = {'positive': 1, 'negative': 0}\n",
        "id2label = {1: 'positive', 0: 'negative'}\n",
        "\n",
        "y = df['sentiment'].map(label2id).tolist()\n",
        "\n",
        "dataset = CustomDataset(X, y, tokenizer)\n",
        "print(dataset[0].keys() )\n",
        "print(\"-------------------------------------------------------------------------\")\n",
        "train_dataset, test_dataset = train_test_split(dataset, test_size=0.2, random_state=42)\n",
        "\n",
        "\n",
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "def compute_metrics(example):\n",
        "  labels = example.label_ids\n",
        "  preds = example.predictions.argmax(-1)\n",
        "\n",
        "  f1 = f1_score(labels, preds, average=\"weighted\")\n",
        "  acc = accuracy_score(labels, preds)\n",
        "\n",
        "  return {'accuracy': acc, \"f1\": f1}\n",
        "\n",
        "\n",
        "from transformers import Trainer, TrainingArguments\n",
        "batch_size = 16\n",
        "model_name = \"distilbert_finetuned_setiment\"\n",
        "\n",
        "args = TrainingArguments(\n",
        "    output_dir = \"output\",\n",
        "    per_device_train_batch_size=batch_size,\n",
        "    per_device_eval_batch_size = batch_size,\n",
        "    learning_rate = 2e-5,\n",
        "    num_train_epochs = 1,\n",
        "    evaluation_strategy = 'epoch'\n",
        ")\n",
        "\n",
        "\n",
        "trainer = Trainer(model=model,\n",
        "                  args=args,\n",
        "                  train_dataset = train_dataset,\n",
        "                  eval_dataset = test_dataset,\n",
        "                  compute_metrics=compute_metrics,\n",
        "                  tokenizer = tokenizer)\n",
        "\n",
        "\n",
        "trainer.train()"
      ],
      "metadata": {
        "id": "Af6jEld-nxdY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.save_model(model_name)"
      ],
      "metadata": {
        "id": "9tRGySoll8dL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"i love this product\"\n",
        "pipe = pipeline('text-classification', model_name)\n",
        "pipe(text)"
      ],
      "metadata": {
        "id": "fNhO6u4NmdMI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "id2label\n"
      ],
      "metadata": {
        "id": "cgRL3tCammpj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "tok = AutoTokenizer.from_pretrained(model_name)\n",
        "mod = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
        "\n",
        "\n",
        "def get_prediction(text):\n",
        "  input_ids = tok.encode(text, return_tensors='pt')\n",
        "  output = mod(input_ids)\n",
        "\n",
        "  preds = torch.nn.functional.softmax(output.logits, dim=-1)\n",
        "\n",
        "  prob = torch.max(preds).item()\n",
        "\n",
        "  idx = torch.argmax(preds).item()\n",
        "  sentiment = id2label[idx]\n",
        "\n",
        "  return {'sentiment':sentiment, 'prob':prob}\n",
        "\n"
      ],
      "metadata": {
        "id": "mM-oH3lJmpDu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"i love this product\"\n",
        "get_prediction(text)"
      ],
      "metadata": {
        "id": "RFz0kv9ctZQS"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
